{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from importlib import reload\n",
    "import sklearn as sk\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 999)\n",
    "pd.set_option(\"display.max_columns\", 999)\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.min_rows', 999)\n",
    "\n",
    "%config IPCompleter.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  district_cd  cohortye  total  gr_droppedout  \\\n",
       "0           0             0        10100      2000    618           83.0   \n",
       "1           1             1        10100      2001    579          100.0   \n",
       "2           2             2        10100      2001    579           84.0   \n",
       "3           3             3        10100      2001    579          103.0   \n",
       "4           4             4        10100      2002    602          143.0   \n",
       "\n",
       "   gr_graduated  gr_iep  gr_ged  gr_stillenrolled  outcome_yrs  srcyear  \\\n",
       "0           407    21.0    57.0              50.0          5.0   200506   \n",
       "1           384    40.0    27.0              28.0          5.0   200706   \n",
       "2           327    30.0    26.0             112.0          4.0   200706   \n",
       "3           397    41.0    29.0               9.0          6.0   200706   \n",
       "4           389    22.0    15.0              33.0          5.0   200806   \n",
       "\n",
       "   subgroup  _name_  gr_local_cnt  year  district_from_df1  num_asian  \\\n",
       "0       1.0     NaN           NaN  2005              10100      269.0   \n",
       "1       1.0     NaN           NaN  2007              10100      360.0   \n",
       "2       1.0     NaN           NaN  2007              10100      360.0   \n",
       "3       1.0     NaN           NaN  2007              10100      360.0   \n",
       "4       1.0     NaN           NaN  2008              10100      382.0   \n",
       "\n",
       "   num_black  num_hisp  num_am_ind  num_white  num_female  num_male  num_lep  \\\n",
       "0     5952.0     918.0        21.0     1884.0         NaN       NaN    300.0   \n",
       "1     5281.0     940.0        24.0     1654.0         NaN       NaN    382.0   \n",
       "2     5281.0     940.0        24.0     1654.0         NaN       NaN    382.0   \n",
       "3     5281.0     940.0        24.0     1654.0         NaN       NaN    382.0   \n",
       "4     4894.0     908.0        27.0     1592.0         NaN       NaN    405.0   \n",
       "\n",
       "   num_free_lunch  num_reduced_lunch  num_multi  num_swd  num_ecdis  num_ell  \\\n",
       "0          5505.0              970.0        0.0      NaN        NaN      NaN   \n",
       "1          3992.0              789.0       77.0      NaN        NaN      NaN   \n",
       "2          3992.0              789.0       77.0      NaN        NaN      NaN   \n",
       "3          3992.0              789.0       77.0      NaN        NaN      NaN   \n",
       "4          4660.0              757.0       96.0      NaN        NaN      NaN   \n",
       "\n",
       "   district_from_faru       ufb     staid      star   totstat       lrev  \\\n",
       "0               10100   5680290  54570126  10225351  64795477   98285968   \n",
       "1               10100  13358464  74675977  10131780  84807757  105784891   \n",
       "2               10100  13358464  74675977  10131780  84807757  105784891   \n",
       "3               10100  13358464  74675977  10131780  84807757  105784891   \n",
       "4               10100  11443927  88986207   9683819  98670026  108582740   \n",
       "\n",
       "     fedrev     totrev  state_aid_total_revenues  star_total_revenues  \\\n",
       "0  16659701  179741146                  0.303604             0.056889   \n",
       "1  13677063  204269711                  0.365575             0.049600   \n",
       "2  13677063  204269711                  0.365575             0.049600   \n",
       "3  13677063  204269711                  0.365575             0.049600   \n",
       "4  12186499  219439265                  0.405516             0.044130   \n",
       "\n",
       "   state_revenues_total_revenues    bded     cadm      tsal      pps      cds  \\\n",
       "0                       0.360493  490999  2118256  54023846  5251097  4501195   \n",
       "1                       0.415175  385910  2055778  55114952  5988074  4266372   \n",
       "2                       0.415175  385910  2055778  55114952  5988074  4266372   \n",
       "3                       0.415175  385910  2055778  55114952  5988074  4266372   \n",
       "4                       0.449646  325611  2333872  57538745  6323772  4632120   \n",
       "\n",
       "       boc    tui1     tui2       ois     oiexp     cser      opmt     tchr  \\\n",
       "0  3728010  188593  6610228  16305802  19303934  1199428  11203660  5165294   \n",
       "1  4793593  541340  7253219  17557992  26611527   602434  11451223  5439024   \n",
       "2  4793593  541340  7253219  17557992  26611527   602434  11451223  5439024   \n",
       "3  4793593  541340  7253219  17557992  26611527   602434  11451223  5439024   \n",
       "4  5340457  734445  7801336  18044340  30170560   428795  11628871  5143395   \n",
       "\n",
       "       heal       oeb  total_fringe_benefits     ound     oth     subtot  \\\n",
       "0  14257866  14441655               33864815  4053261  564400  163407524   \n",
       "1  16966397  11086334               33491755  3264726  989999  174368894   \n",
       "2  16966397  11086334               33491755  3264726  989999  174368894   \n",
       "3  16966397  11086334               33491755  3264726  989999  174368894   \n",
       "4  17442327  13876660               36462382  3527941  760170  186053417   \n",
       "\n",
       "     trans      dsp      dsi       texp  total_unexpended_surplus_funds_t  \\\n",
       "0  5972182  7669294  5365766  182414766                          0.031139   \n",
       "1  6153173  7356028  6733231  194611326                          0.068642   \n",
       "2  6153173  7356028  6733231  194611326                          0.068642   \n",
       "3  6153173  7356028  6733231  194611326                          0.068642   \n",
       "4  6320002  8410609  6874804  207658832                          0.055109   \n",
       "\n",
       "   revenue_expenditures       var  dcaadm     rev_pupil     exp_pupil  \\\n",
       "0              -2673620 -0.014657   10559  17022.553840  17275.761530   \n",
       "1               9658385  0.049629   10430  19584.823682  18658.804027   \n",
       "2               9658385  0.049629   10430  19584.823682  18658.804027   \n",
       "3               9658385  0.049629   10430  19584.823682  18658.804027   \n",
       "4              11780433  0.056730   10702  20504.509905  19403.740609   \n",
       "\n",
       "   av_twpu  inc_twpu       pwr      apwr       cwr  instructional_salaries  \\\n",
       "0   244659     93587  0.706290  0.789764  0.748027                83809950   \n",
       "1   268181     99117  0.628353  0.725600  0.676977                87720983   \n",
       "2   268181     99117  0.628353  0.725600  0.676977                87720983   \n",
       "3   268181     99117  0.628353  0.725600  0.676977                87720983   \n",
       "4   310466    103451  0.650327  0.694768  0.672548                91879434   \n",
       "\n",
       "   instructional_fringe_benefits    ins_fb  adjusted_expenditures__subtotal  \\\n",
       "0                   3.117730e+07  0.170914                        162986931   \n",
       "1                   3.087779e+07  0.158664                        173595554   \n",
       "2                   3.087779e+07  0.158664                        173595554   \n",
       "3                   3.087779e+07  0.158664                        173595554   \n",
       "4                   3.307660e+07  0.159283                        185202972   \n",
       "\n",
       "           ie1  ie1_total  ie2_instructional_expenditures_i       ie2  \\\n",
       "0  109912705.0   0.602543                      1.410900e+08  0.773457   \n",
       "1  122127069.0   0.627543                      1.530049e+08  0.786207   \n",
       "2  122127069.0   0.627543                      1.530049e+08  0.786207   \n",
       "3  122127069.0   0.627543                      1.530049e+08  0.786207   \n",
       "4  130585775.0   0.628800                      1.636624e+08  0.788131   \n",
       "\n",
       "   ie3_instructional_expenditures_i  ie3_adj_exp  loc_eff_rate  districtid  \\\n",
       "0                      1.409014e+08     0.864495         26.51     10100.0   \n",
       "1                      1.524635e+08     0.878269         21.95     10100.0   \n",
       "2                      1.524635e+08     0.878269         21.95     10100.0   \n",
       "3                      1.524635e+08     0.878269         21.95     10100.0   \n",
       "4                      1.629279e+08     0.879726         21.25     10100.0   \n",
       "\n",
       "          name county_name district_name  \n",
       "0  albany city      Albany   albany city  \n",
       "1  albany city      Albany   albany city  \n",
       "2  albany city      Albany   albany city  \n",
       "3  albany city      Albany   albany city  \n",
       "4  albany city      Albany   albany city  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>district_cd</th>\n      <th>cohortye</th>\n      <th>total</th>\n      <th>gr_droppedout</th>\n      <th>gr_graduated</th>\n      <th>gr_iep</th>\n      <th>gr_ged</th>\n      <th>gr_stillenrolled</th>\n      <th>outcome_yrs</th>\n      <th>srcyear</th>\n      <th>subgroup</th>\n      <th>_name_</th>\n      <th>gr_local_cnt</th>\n      <th>year</th>\n      <th>district_from_df1</th>\n      <th>num_asian</th>\n      <th>num_black</th>\n      <th>num_hisp</th>\n      <th>num_am_ind</th>\n      <th>num_white</th>\n      <th>num_female</th>\n      <th>num_male</th>\n      <th>num_lep</th>\n      <th>num_free_lunch</th>\n      <th>num_reduced_lunch</th>\n      <th>num_multi</th>\n      <th>num_swd</th>\n      <th>num_ecdis</th>\n      <th>num_ell</th>\n      <th>district_from_faru</th>\n      <th>ufb</th>\n      <th>staid</th>\n      <th>star</th>\n      <th>totstat</th>\n      <th>lrev</th>\n      <th>fedrev</th>\n      <th>totrev</th>\n      <th>state_aid_total_revenues</th>\n      <th>star_total_revenues</th>\n      <th>state_revenues_total_revenues</th>\n      <th>bded</th>\n      <th>cadm</th>\n      <th>tsal</th>\n      <th>pps</th>\n      <th>cds</th>\n      <th>boc</th>\n      <th>tui1</th>\n      <th>tui2</th>\n      <th>ois</th>\n      <th>oiexp</th>\n      <th>cser</th>\n      <th>opmt</th>\n      <th>tchr</th>\n      <th>heal</th>\n      <th>oeb</th>\n      <th>total_fringe_benefits</th>\n      <th>ound</th>\n      <th>oth</th>\n      <th>subtot</th>\n      <th>trans</th>\n      <th>dsp</th>\n      <th>dsi</th>\n      <th>texp</th>\n      <th>total_unexpended_surplus_funds_t</th>\n      <th>revenue_expenditures</th>\n      <th>var</th>\n      <th>dcaadm</th>\n      <th>rev_pupil</th>\n      <th>exp_pupil</th>\n      <th>av_twpu</th>\n      <th>inc_twpu</th>\n      <th>pwr</th>\n      <th>apwr</th>\n      <th>cwr</th>\n      <th>instructional_salaries</th>\n      <th>instructional_fringe_benefits</th>\n      <th>ins_fb</th>\n      <th>adjusted_expenditures__subtotal</th>\n      <th>ie1</th>\n      <th>ie1_total</th>\n      <th>ie2_instructional_expenditures_i</th>\n      <th>ie2</th>\n      <th>ie3_instructional_expenditures_i</th>\n      <th>ie3_adj_exp</th>\n      <th>loc_eff_rate</th>\n      <th>districtid</th>\n      <th>name</th>\n      <th>county_name</th>\n      <th>district_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>10100</td>\n      <td>2000</td>\n      <td>618</td>\n      <td>83.0</td>\n      <td>407</td>\n      <td>21.0</td>\n      <td>57.0</td>\n      <td>50.0</td>\n      <td>5.0</td>\n      <td>200506</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2005</td>\n      <td>10100</td>\n      <td>269.0</td>\n      <td>5952.0</td>\n      <td>918.0</td>\n      <td>21.0</td>\n      <td>1884.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>300.0</td>\n      <td>5505.0</td>\n      <td>970.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10100</td>\n      <td>5680290</td>\n      <td>54570126</td>\n      <td>10225351</td>\n      <td>64795477</td>\n      <td>98285968</td>\n      <td>16659701</td>\n      <td>179741146</td>\n      <td>0.303604</td>\n      <td>0.056889</td>\n      <td>0.360493</td>\n      <td>490999</td>\n      <td>2118256</td>\n      <td>54023846</td>\n      <td>5251097</td>\n      <td>4501195</td>\n      <td>3728010</td>\n      <td>188593</td>\n      <td>6610228</td>\n      <td>16305802</td>\n      <td>19303934</td>\n      <td>1199428</td>\n      <td>11203660</td>\n      <td>5165294</td>\n      <td>14257866</td>\n      <td>14441655</td>\n      <td>33864815</td>\n      <td>4053261</td>\n      <td>564400</td>\n      <td>163407524</td>\n      <td>5972182</td>\n      <td>7669294</td>\n      <td>5365766</td>\n      <td>182414766</td>\n      <td>0.031139</td>\n      <td>-2673620</td>\n      <td>-0.014657</td>\n      <td>10559</td>\n      <td>17022.553840</td>\n      <td>17275.761530</td>\n      <td>244659</td>\n      <td>93587</td>\n      <td>0.706290</td>\n      <td>0.789764</td>\n      <td>0.748027</td>\n      <td>83809950</td>\n      <td>3.117730e+07</td>\n      <td>0.170914</td>\n      <td>162986931</td>\n      <td>109912705.0</td>\n      <td>0.602543</td>\n      <td>1.410900e+08</td>\n      <td>0.773457</td>\n      <td>1.409014e+08</td>\n      <td>0.864495</td>\n      <td>26.51</td>\n      <td>10100.0</td>\n      <td>albany city</td>\n      <td>Albany</td>\n      <td>albany city</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>10100</td>\n      <td>2001</td>\n      <td>579</td>\n      <td>100.0</td>\n      <td>384</td>\n      <td>40.0</td>\n      <td>27.0</td>\n      <td>28.0</td>\n      <td>5.0</td>\n      <td>200706</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2007</td>\n      <td>10100</td>\n      <td>360.0</td>\n      <td>5281.0</td>\n      <td>940.0</td>\n      <td>24.0</td>\n      <td>1654.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>382.0</td>\n      <td>3992.0</td>\n      <td>789.0</td>\n      <td>77.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10100</td>\n      <td>13358464</td>\n      <td>74675977</td>\n      <td>10131780</td>\n      <td>84807757</td>\n      <td>105784891</td>\n      <td>13677063</td>\n      <td>204269711</td>\n      <td>0.365575</td>\n      <td>0.049600</td>\n      <td>0.415175</td>\n      <td>385910</td>\n      <td>2055778</td>\n      <td>55114952</td>\n      <td>5988074</td>\n      <td>4266372</td>\n      <td>4793593</td>\n      <td>541340</td>\n      <td>7253219</td>\n      <td>17557992</td>\n      <td>26611527</td>\n      <td>602434</td>\n      <td>11451223</td>\n      <td>5439024</td>\n      <td>16966397</td>\n      <td>11086334</td>\n      <td>33491755</td>\n      <td>3264726</td>\n      <td>989999</td>\n      <td>174368894</td>\n      <td>6153173</td>\n      <td>7356028</td>\n      <td>6733231</td>\n      <td>194611326</td>\n      <td>0.068642</td>\n      <td>9658385</td>\n      <td>0.049629</td>\n      <td>10430</td>\n      <td>19584.823682</td>\n      <td>18658.804027</td>\n      <td>268181</td>\n      <td>99117</td>\n      <td>0.628353</td>\n      <td>0.725600</td>\n      <td>0.676977</td>\n      <td>87720983</td>\n      <td>3.087779e+07</td>\n      <td>0.158664</td>\n      <td>173595554</td>\n      <td>122127069.0</td>\n      <td>0.627543</td>\n      <td>1.530049e+08</td>\n      <td>0.786207</td>\n      <td>1.524635e+08</td>\n      <td>0.878269</td>\n      <td>21.95</td>\n      <td>10100.0</td>\n      <td>albany city</td>\n      <td>Albany</td>\n      <td>albany city</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>10100</td>\n      <td>2001</td>\n      <td>579</td>\n      <td>84.0</td>\n      <td>327</td>\n      <td>30.0</td>\n      <td>26.0</td>\n      <td>112.0</td>\n      <td>4.0</td>\n      <td>200706</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2007</td>\n      <td>10100</td>\n      <td>360.0</td>\n      <td>5281.0</td>\n      <td>940.0</td>\n      <td>24.0</td>\n      <td>1654.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>382.0</td>\n      <td>3992.0</td>\n      <td>789.0</td>\n      <td>77.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10100</td>\n      <td>13358464</td>\n      <td>74675977</td>\n      <td>10131780</td>\n      <td>84807757</td>\n      <td>105784891</td>\n      <td>13677063</td>\n      <td>204269711</td>\n      <td>0.365575</td>\n      <td>0.049600</td>\n      <td>0.415175</td>\n      <td>385910</td>\n      <td>2055778</td>\n      <td>55114952</td>\n      <td>5988074</td>\n      <td>4266372</td>\n      <td>4793593</td>\n      <td>541340</td>\n      <td>7253219</td>\n      <td>17557992</td>\n      <td>26611527</td>\n      <td>602434</td>\n      <td>11451223</td>\n      <td>5439024</td>\n      <td>16966397</td>\n      <td>11086334</td>\n      <td>33491755</td>\n      <td>3264726</td>\n      <td>989999</td>\n      <td>174368894</td>\n      <td>6153173</td>\n      <td>7356028</td>\n      <td>6733231</td>\n      <td>194611326</td>\n      <td>0.068642</td>\n      <td>9658385</td>\n      <td>0.049629</td>\n      <td>10430</td>\n      <td>19584.823682</td>\n      <td>18658.804027</td>\n      <td>268181</td>\n      <td>99117</td>\n      <td>0.628353</td>\n      <td>0.725600</td>\n      <td>0.676977</td>\n      <td>87720983</td>\n      <td>3.087779e+07</td>\n      <td>0.158664</td>\n      <td>173595554</td>\n      <td>122127069.0</td>\n      <td>0.627543</td>\n      <td>1.530049e+08</td>\n      <td>0.786207</td>\n      <td>1.524635e+08</td>\n      <td>0.878269</td>\n      <td>21.95</td>\n      <td>10100.0</td>\n      <td>albany city</td>\n      <td>Albany</td>\n      <td>albany city</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>10100</td>\n      <td>2001</td>\n      <td>579</td>\n      <td>103.0</td>\n      <td>397</td>\n      <td>41.0</td>\n      <td>29.0</td>\n      <td>9.0</td>\n      <td>6.0</td>\n      <td>200706</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2007</td>\n      <td>10100</td>\n      <td>360.0</td>\n      <td>5281.0</td>\n      <td>940.0</td>\n      <td>24.0</td>\n      <td>1654.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>382.0</td>\n      <td>3992.0</td>\n      <td>789.0</td>\n      <td>77.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10100</td>\n      <td>13358464</td>\n      <td>74675977</td>\n      <td>10131780</td>\n      <td>84807757</td>\n      <td>105784891</td>\n      <td>13677063</td>\n      <td>204269711</td>\n      <td>0.365575</td>\n      <td>0.049600</td>\n      <td>0.415175</td>\n      <td>385910</td>\n      <td>2055778</td>\n      <td>55114952</td>\n      <td>5988074</td>\n      <td>4266372</td>\n      <td>4793593</td>\n      <td>541340</td>\n      <td>7253219</td>\n      <td>17557992</td>\n      <td>26611527</td>\n      <td>602434</td>\n      <td>11451223</td>\n      <td>5439024</td>\n      <td>16966397</td>\n      <td>11086334</td>\n      <td>33491755</td>\n      <td>3264726</td>\n      <td>989999</td>\n      <td>174368894</td>\n      <td>6153173</td>\n      <td>7356028</td>\n      <td>6733231</td>\n      <td>194611326</td>\n      <td>0.068642</td>\n      <td>9658385</td>\n      <td>0.049629</td>\n      <td>10430</td>\n      <td>19584.823682</td>\n      <td>18658.804027</td>\n      <td>268181</td>\n      <td>99117</td>\n      <td>0.628353</td>\n      <td>0.725600</td>\n      <td>0.676977</td>\n      <td>87720983</td>\n      <td>3.087779e+07</td>\n      <td>0.158664</td>\n      <td>173595554</td>\n      <td>122127069.0</td>\n      <td>0.627543</td>\n      <td>1.530049e+08</td>\n      <td>0.786207</td>\n      <td>1.524635e+08</td>\n      <td>0.878269</td>\n      <td>21.95</td>\n      <td>10100.0</td>\n      <td>albany city</td>\n      <td>Albany</td>\n      <td>albany city</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>10100</td>\n      <td>2002</td>\n      <td>602</td>\n      <td>143.0</td>\n      <td>389</td>\n      <td>22.0</td>\n      <td>15.0</td>\n      <td>33.0</td>\n      <td>5.0</td>\n      <td>200806</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2008</td>\n      <td>10100</td>\n      <td>382.0</td>\n      <td>4894.0</td>\n      <td>908.0</td>\n      <td>27.0</td>\n      <td>1592.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>405.0</td>\n      <td>4660.0</td>\n      <td>757.0</td>\n      <td>96.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10100</td>\n      <td>11443927</td>\n      <td>88986207</td>\n      <td>9683819</td>\n      <td>98670026</td>\n      <td>108582740</td>\n      <td>12186499</td>\n      <td>219439265</td>\n      <td>0.405516</td>\n      <td>0.044130</td>\n      <td>0.449646</td>\n      <td>325611</td>\n      <td>2333872</td>\n      <td>57538745</td>\n      <td>6323772</td>\n      <td>4632120</td>\n      <td>5340457</td>\n      <td>734445</td>\n      <td>7801336</td>\n      <td>18044340</td>\n      <td>30170560</td>\n      <td>428795</td>\n      <td>11628871</td>\n      <td>5143395</td>\n      <td>17442327</td>\n      <td>13876660</td>\n      <td>36462382</td>\n      <td>3527941</td>\n      <td>760170</td>\n      <td>186053417</td>\n      <td>6320002</td>\n      <td>8410609</td>\n      <td>6874804</td>\n      <td>207658832</td>\n      <td>0.055109</td>\n      <td>11780433</td>\n      <td>0.056730</td>\n      <td>10702</td>\n      <td>20504.509905</td>\n      <td>19403.740609</td>\n      <td>310466</td>\n      <td>103451</td>\n      <td>0.650327</td>\n      <td>0.694768</td>\n      <td>0.672548</td>\n      <td>91879434</td>\n      <td>3.307660e+07</td>\n      <td>0.159283</td>\n      <td>185202972</td>\n      <td>130585775.0</td>\n      <td>0.628800</td>\n      <td>1.636624e+08</td>\n      <td>0.788131</td>\n      <td>1.629279e+08</td>\n      <td>0.879726</td>\n      <td>21.25</td>\n      <td>10100.0</td>\n      <td>albany city</td>\n      <td>Albany</td>\n      <td>albany city</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df = pd.read_csv(\"./df_with_counties_v1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "X = df.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'gr_droppedout', 'gr_graduated', 'gr_iep', 'gr_ged', 'gr_stillenrolled', '_name_', 'district_from_df1', 'district_from_faru', 'districtid'])\n",
    "y_grad = df.gr_graduated\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_grad, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features), ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "rf = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['district_cd', 'cohortye', 'total', 'outcome_yrs', 'srcyear',\n",
       "       'subgroup', 'gr_local_cnt', 'year', 'num_asian', 'num_black',\n",
       "       'num_hisp', 'num_am_ind', 'num_white', 'num_female', 'num_male',\n",
       "       'num_le...\n",
       "       'ie2_instructional_expenditures_i', 'ie2',\n",
       "       'ie3_instructional_expenditures_i', 'ie3_adj_exp', 'loc_eff_rate'],\n",
       "      dtype='object')),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  Index(['name', 'county_name', 'district_name'], dtype='object'))])),\n",
       "                ('classifier', RandomForestClassifier())])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ec9259977c5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/src/CSE6242/.venv/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/CSE6242/.venv/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_final_estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/CSE6242/.venv/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \"\"\"\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/CSE6242/.venv/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    684\u001b[0m             delayed(_accumulate_prediction)(e.predict_proba, X, all_proba,\n\u001b[1;32m    685\u001b[0m                                             lock)\n\u001b[0;32m--> 686\u001b[0;31m             for e in self.estimators_)\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mproba\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/CSE6242/.venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/CSE6242/.venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/CSE6242/.venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/CSE6242/.venv/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/CSE6242/.venv/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/CSE6242/.venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/CSE6242/.venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/CSE6242/.venv/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_accumulate_prediction\u001b[0;34m(predict, X, out, lock)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0mcomplains\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mthere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/CSE6242/.venv/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/tree/_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.Tree.predict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msklearn/tree/_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.Tree.predict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/src/CSE6242/.venv/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36mget_shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;34m\"\"\"Get shape of a matrix.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNeighborsClassifier(n_neighbors=3)\n",
      "model score: 0.217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    NuSVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier()\n",
    "    ]\n",
    "    \n",
    "for classifier in classifiers:\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', classifier)])\n",
    "    pipe.fit(X_train, y_train)   \n",
    "    print(classifier)\n",
    "    print(\"model score: %.3f\" % pipe.score(X_test, y_test))"
   ]
  },
  {
   "source": [
    "param_grid = { \n",
    "    'classifier__n_estimators': [200, 500],\n",
    "    'classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'classifier__max_depth' : [4,5,6,7,8],\n",
    "    'classifier__criterion' :['gini', 'entropy']}from sklearn.model_selection import GridSearchCVCV = GridSearchCV(rf, param_grid, n_jobs= 1)\n",
    "                  \n",
    "CV.fit(X_train, y_train)  \n",
    "print(CV.best_params_)    \n",
    "print(CV.best_score_)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}